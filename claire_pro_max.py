import os
import json
import sqlite3
from datetime import datetime, timedelta
from typing import List, Dict, Any
import replicate
from PIL import Image
import io
import base64
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage, PageBreak
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.units import cm

from langchain_groq import ChatGroq
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
import chromadb

import gradio as gr
from elevenlabs.client import ElevenLabs  # CORRIG√â : Nouvelle API v2
import dotenv

dotenv.load_dotenv()

# ================== Cl√©s API ==================
CLE_GROQ = os.getenv("CLE_GROQ")
CLE_ELEVENLABS = os.getenv("CLE_ELEVENLABS")
JETON_REPLICATE = os.getenv("JETON_REPLICATE")  # Obligatoire pour Flux

os.environ["REPLICATE_API_TOKEN"] = JETON_REPLICATE

llm = ChatGroq(model="llama-3.1-70b-versatile", temperature=0.6, api_key=CLE_GROQ)

ID_VOIX = "21m00Tcm4TlvDq8ikWAM"  # Rachel, la voix pr√©f√©r√©e des enfants

# Client ElevenLabs global (CORRIG√â)
client_eleven = ElevenLabs(api_key=CLE_ELEVENLABS)

# ================== Base de Donn√©es + Enregistrements ==================
BASE = "claire_pro.db"

def initialiser_base():
    conn = sqlite3.connect(BASE)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS enfants (
        nom TEXT PRIMARY KEY, donnees TEXT)''')
    c.execute('''CREATE TABLE IF NOT EXISTS seances (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        nom TEXT, horodatage TEXT, categorie TEXT, mot TEXT, 
        reaction TEXT, image_b64 TEXT, chemin_audio TEXT)''')
    conn.commit()
    conn.close()

initialiser_base()

# ================== G√©n√©ration d'Images Flux (Style R√©aliste Ultra-Doux) ==================
def generer_image(mot: str) -> str:
    invite = f"photo r√©aliste tr√®s douce et lumineuse pour enfant autiste 2-4 ans, un seul {mot} au centre, fond blanc ou pastel tr√®s clair, style livre cartonn√© Petit Ours Brun, lumi√®re chaude, hyper d√©taill√©, pas de texte, pas de bordure, qualit√© maximale"
    
    sortie = replicate.run(
        "black-forest-labs/flux-pro",
        input={"prompt": invite, "num_outputs": 1, "aspect_ratio": "1:1", "output_format": "png"}
    )
    url_img = sortie[0]
    
    import requests
    donnees_img = requests.get(url_img).content
    b64 = base64.b64encode(donnees_img).decode()
    return f"data:image/png;base64,{b64}"

# ================== RAG ==================
lecteur = SimpleDirectoryReader("data", required_exts=[".docx"])
documents = lecteur.load_data()
client_chroma = chromadb.PersistentClient(path="chroma_db_pro")
collection = client_chroma.get_or_create_collection("vocabulaire")
magasin_vecteurs = ChromaVectorStore(chroma_collection=collection)
contexte_stockage = StorageContext.from_defaults(vector_store=magasin_vecteurs)
index = VectorStoreIndex.from_documents(documents, contexte_stockage=contexte_stockage)

# ================== Invite Syst√®me (Version Ultime) ==================
INVITE_SYSTEME = """
Tu t'appelles Claire, orthophoniste sp√©cialis√©e autisme √† Paris.
Tu parles exclusivement en fran√ßais, voix extr√™mement douce et lente.
√Çge langagier de l'enfant : {age_lang}.
R√®gles d'or :
- Maximum 6 mots par phrase
- R√©p√©ter chaque mot cible 3 fois
- Pauses tr√®s longues : ‚Ä¶‚Ä¶‚Ä¶
- Encouragement √©norme √† la moindre micro-r√©action
- Tu ne demandes jamais "r√©p√®te", tu mod√©lises seulement
Commence toujours par : "Bonjour mon petit c≈ìur [pr√©nom]‚Ä¶ c'est Claire‚Ä¶‚Ä¶"
Quand tu dis un mot, √©cris-le en MAJUSCULES pour que le syst√®me g√©n√®re l'image.
Exemple : Regarde‚Ä¶‚Ä¶ CHAT‚Ä¶‚Ä¶ chat‚Ä¶‚Ä¶ chat‚Ä¶‚Ä¶ il dort‚Ä¶‚Ä¶ miam miam‚Ä¶‚Ä¶
"""

# ================== Fonction de Dialogue Principale ==================
def discuter_avec_claire(message: str, historique: List, etat_enfant: dict, categorie: str):
    etat = json.loads(etat_enfant) if isinstance(etat_enfant, str) else {}
    nom = etat.get("nom", "L√©o")
    
    # RAG : R√©cup√©rer vocabulaire du jour
    reponse = index.as_query_engine(similarity_top_k=12).query(
        f"Liste 8 mots tr√®s simples en fran√ßais de la cat√©gorie '{categorie}' pour √¢ge langagier {etat.get('age_langage','2 ans')}. Retourne seulement les mots s√©par√©s par virgule."
    )
    mots_du_jour = [m.strip().lower() for m in reponse.response.split(",")[:5]]
    
    invite = INVITE_SYSTEME.format(age_lang=etat.get("age_langage", "2 ans"))
    complet = f"""{invite}

Pr√©nom : {nom}
Cat√©gorie : {categorie}
Mots du jour : {", ".join(mots_du_jour)}

Historique r√©cent : {historique[-8:]}

L'enfant dit ou fait : "{message or 'Ôºàsilence ou regarde ailleursÔºâ'}"

R√©ponds exactement comme Claire le ferait, avec majuscules sur les mots cibles pour d√©clencher l'image.
"""
    reponse_claire = llm.invoke(complet).content.strip()
    
    # G√©n√©ration automatique d'images
    images = []
    for mot in mots_du_jour:
        if mot.upper() in reponse_claire:
            img_b64 = generer_image(mot)
            images.append(img_b64)
            
            # Enregistrer la s√©ance
            conn = sqlite3.connect(BASE)
            c = conn.cursor()
            c.execute("INSERT INTO seances (nom,horodatage,categorie,mot,reaction,image_b64) VALUES (?,?,?,?,?,?)",
                     (nom, datetime.now().isoformat(), categorie, mot, message or "regarde √©cran", img_b64))
            conn.commit()
            conn.close()
    
    # Audio CORRIG√â pour ElevenLabs v2
    audio_gen = client_eleven.text_to_speech.convert(
        text=reponse_claire,
        voice_id=ID_VOIX,
        model_id="eleven_turbo_v2_5",
        output_format="mp3_44100_128"
    )
    
    # Sauvegarde pour Gradio
    chemin_audio = "temp_audio.mp3"
    with open(chemin_audio, "wb") as f:
        for chunk in audio_gen:
            f.write(chunk)
    
    return reponse_claire, chemin_audio, images if images else None

# [Le reste du code reste identique : generer_rapport_semaine, interface Gradio, etc.]
# ... (copie le reste de ton fichier original ici pour la partie rapport et Gradio)

# Exemple pour la fin (ajoute si manquant)
with gr.Blocks(title="Claire Pro Max ‚Äì Orthophoniste IA Autisme", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ü¶ã Claire Pro Max\n**L'orthophoniste virtuelle que tous les enfants adorent**")
    
    with gr.Row():
        saisie_nom = gr.Textbox(label="Pr√©nom de l'enfant", value="L√©o", placeholder="L√©o, Emma, Noah‚Ä¶")
        categorie = gr.Dropdown(
            choices=["famille", "animaux familiers", "nourriture", "actions", "objets & jouets", "√©motions", "couleurs", "corps"],
            value="animaux familiers", label="Cat√©gorie du jour"
        )
    
    chatbot = gr.Chatbot(height=500, avatar_images=["üßë‚Äç‚öïÔ∏è", "üë∂"])
    saisie_msg = gr.Textbox(placeholder="L'enfant peut parler ici‚Ä¶ ou rester silencieux, Claire continue quand m√™me ‚ù§Ô∏è", label="Message / Observation (ex: regarde l'√©cran, pointe, vocalise, silence)")
    
    with gr.Row():
        audio = gr.Audio(label="Voix de Claire", autoplay=True, streaming=False, type="filepath")
        galerie = gr.Gallery(label="Photos g√©n√©r√©es aujourd'hui", height=400)
    
    btn_rapport = gr.Button("üìÑ G√©n√©rer le rapport PDF de cette semaine", variant="primary")
    sortie_rapport = gr.File(label="Rapport t√©l√©chargeable")
    
    def mettre_a_jour_etat(nom):
        conn = sqlite3.connect(BASE)
        c = conn.cursor()
        c.execute("SELECT donnees FROM enfants WHERE nom=?", (nom,))
        ligne = c.fetchone()
        conn.close()
        if ligne:
            return json.dumps(json.loads(ligne[0]))
        else:
            defaut = {"nom": nom, "age_langage": "2 ans", "mots_maitrises": ["maman","papa"]}
            return json.dumps(defaut)
    
    def envoyer(message, historique, json_etat, cat):
        etat = json.loads(json_etat)
        reponse, chemin_audio, images = discuter_avec_claire(message, historique, etat, cat)
        historique.append(("üë∂ " + (message or "(regarde / silencieux)"), None))
        historique.append(("üßë‚Äç‚öïÔ∏è " + reponse, images[0] if images else None))
        return historique, chemin_audio, images or [], ""
    
    saisie_msg.submit(envoyer, [saisie_msg, chatbot, gr.State(value=""), categorie], [chatbot, audio, galerie, saisie_msg])
    
    btn_rapport.click(generer_rapport_semaine, saisie_nom, sortie_rapport)

demo.launch(share=True, server_port=7860)
